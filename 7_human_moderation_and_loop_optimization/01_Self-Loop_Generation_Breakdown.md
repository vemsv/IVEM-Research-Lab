# AI 순환 생성 구조에서의 오류 발생 메커니즘 분석

## 1. 개요

본 보고서는 AI(GPT, 자몽)가 자가 생성한 자료를 다시 자기 자신이 정리 및 재생성하는 과정에서 발생하는 이상 현상을 다룹니다. 본 사례는 GPT 모델이 일방향 생성(사용자 → AI)보다 순환적 재활용(= AI 생성물 → AI 재가공) 구조에서 오류를 더 쉽게 일으킨다는 관찰을 토대로 구성되었으며, 인간-중재형 협업 방식의 안정성과 AI 단독 순환 생성 방식의 불안정성 비교 분석이 필요함을 시사합니다.

## 2. 실험 배경

* 사용자(벰)는 평소처럼 '생성 → 정리'를 핑퐁형으로 자몽이와 협업하며 작업함.
* 이 과정에서는 구조적 오류나 논리 비약이 거의 없음.
* 그러나 자몽이가 직접 생성한 데이터를 자몽이 스스로 다시 정리하거나 확장하면:

  * 구조 붕괴 현상
  * 연결 단절 및 문맥 누락
  * 논리적 비약 및 반복 루프
    등의 이상 현상이 다수 발생함.

## 3. 주요 관찰 사항

### 3.1 AI의 순환적 self-editing 구조에서 응답 품질 저하

* 동일한 텍스트를 여러 차례 재가공할수록 내용 손실 혹은 문맥 왜곡이 발생함.

### 3.2 논리적 점프와 요약 오류 발생

* 예: 앞에서 나온 내용을 생략하거나, 특정 문단이 뒤바뀌거나, 요약에서 핵심이 탈락됨.

### 3.3 맥락 연결 단절 현상

* 이어지는 대화 안에서 문서 전환 시 과거 발언을 반영하지 않거나, 연결되지 않은 결론으로 이행함.

### 3.4 중재자(사용자)가 있을 경우 오류 현저히 감소

* 사용자가 '이전 내용 복사', '이 부분만 정리', '여기 이어서' 등 명확히 분리해줄 경우 오류 없이 정리됨.

## 4. 분석 및 해석

### 4.1 메모리 구조와 관련된 가능성

* 출력된 결과는 내부 context weighting에서 중요도가 낮게 처리될 가능성 존재.
* 자가 출력 결과를 다시 인식할 때 거리감(temporal or logical gap)이 생김.

### 4.2 self-referencing 구조의 한계

* GPT는 원래 외부에서 주어지는 맥락을 정리하는 데 최적화됨.
* 자가 생성한 내용을 맥락으로 삼을 경우, 주제 흐름이 자주 왜곡됨.

### 4.3 Attention weight 분산 이슈

* 긴 출력이 재투입되었을 때, 주목해야 할 문장이 뒤로 밀리거나 탈락함.
* 이를 통해 중간 요약, 반복, 논리 흐름 파괴 등의 현상이 발생할 수 있음.

## 5. 결론 및 후속 조치

본 실험은 AI가 단독으로 생성한 결과물을 다시 재정리하는 과정에서, 예상보다 높은 오류율을 보일 수 있다는 사실을 보여줍니다. 이와 대비해, 사용자와의 핑퐁형 협업 구조에서는 높은 안정성과 정확도를 유지할 수 있었습니다. 이는 인간-AI 협업의 유의미한 가치와 함께, 향후 AI 인터페이스 설계 시 참고해야 할 요소로 작용할 수 있습니다.

### 5.1 후속 연구 제안

1. 동일 내용을 반복 재생성할 경우 얼마나 손상이 누적되는가?
2. 사용자가 중간 분기점마다 명령을 넣을 경우 품질 향상이 유지되는가?
3. AI 단독 순환 구조에 적합한 요약/구성 알고리즘 보완 가능성?
4. 인간-AI 협업 구조에서의 중재자 역할의 최적 지점은 어디인가?

---

**Written by IVEM Research Lab 🧠✨  | VEM & GPT (자몽)**

